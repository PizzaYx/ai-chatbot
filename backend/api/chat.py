from ninja import Router, Schema
from django.http import StreamingHttpResponse
from django.contrib.auth.models import User
from typing import List, Optional
import json
import uuid
import time
from datetime import datetime
# LlamaIndex
from llama_index.core import VectorStoreIndex, StorageContext, Settings
from llama_index.core.llms import ChatMessage as LlamaChatMessage
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.core.tools import QueryEngineTool, ToolMetadata
from llama_index.core.query_engine import RouterQueryEngine
from llama_index.core.selectors import EmbeddingSingleSelector

# Local Imports
from chat.models import ChatSession, ChatMessage
from documents.services import get_vector_store, init_llm, init_embedding
from core.mcp_tools import get_mcp_tools, get_tool_server_map
from api.auth import decode_token  # å¯¼å…¥ JWT è§£ç å‡½æ•°

router = Router(tags=["Chat"])


def get_current_user_from_request(request) -> Optional[User]:
    """
    ä»è¯·æ±‚çš„ Authorization header ä¸­æå–å¹¶éªŒè¯ç”¨æˆ·
    è¿™æ˜¯ä¸€ä¸ªå¯é€‰çš„è®¤è¯ - å¦‚æœæ²¡æœ‰ Token æˆ– Token æ— æ•ˆï¼Œè¿”å› None
    """
    auth_header = request.headers.get("Authorization", "")
    if not auth_header.startswith("Bearer "):
        return None
    
    token = auth_header[7:]  # å»æ‰ "Bearer " å‰ç¼€
    payload = decode_token(token)
    if payload is None:
        return None
    
    user_id = payload.get("user_id")
    try:
        return User.objects.get(id=user_id)
    except User.DoesNotExist:
        return None

# --- Schemas ---
class MessageSchema(Schema):
    role: str  # 'user' | 'ai'
    text: str
    sources: Optional[List[dict]] = None
    elapsed: Optional[int] = None # è€—æ—¶ (ms)

class ChatRequest(Schema):
    messages: List[MessageSchema] 
    session_id: Optional[str] = None # å‰ç«¯ä¼ æ¥çš„ä¼šè¯ID
    model: Optional[str] = None
    use_rag: Optional[bool] = True

class ChatResponse(Schema):
    session_id: str
    message: MessageSchema

class SessionSchema(Schema):
    id: str
    title: str
    updated_at: str
    message_count: int

# --- Core Logic ---

def get_chat_history(session_id: str) -> List[LlamaChatMessage]:
    """ä»æ•°æ®åº“åŠ è½½å†å²è®°å½•"""
    if not session_id:
        return []
    
    # è·å–æœ€è¿‘ 20 æ¡æ¶ˆæ¯ (å…ˆæŒ‰æ—¶é—´å€’åºå–æœ€æ–°çš„ï¼Œå†è½¬å›æ­£åº)
    db_messages = ChatMessage.objects.filter(
        session_id=session_id
    ).order_by('-created_at')[:20]
    
    # è½¬å›æ­£åº
    db_messages = reversed(db_messages)
    
    history = []
    for msg in db_messages:
        # æ˜ å°„æ•°æ®åº“è§’è‰²åˆ° LlamaIndex è§’è‰² (ai -> assistant)
        role = "assistant" if msg.role == "ai" else msg.role
        history.append(LlamaChatMessage(role=role, content=msg.content))
    return history

def stream_generator(current_message: str, history: List[LlamaChatMessage], model_name: str, use_rag: bool, session_id: str):
    """
    æµå¼ç”Ÿæˆå™¨å‡½æ•°: MCP å·¥å…· / æ··åˆæ£€ç´¢ -> å†³å®š Tool/RAG/Chat -> Stream
    """
    start_time = time.time() # å¼€å§‹è®¡æ—¶
    llm = init_llm()
    embed_model = init_embedding()
    Settings.llm = llm
    Settings.embed_model = embed_model
    
    # --- 0. åŠ è½½ MCP å·¥å…· ---
    mcp_tools = get_mcp_tools()
    if mcp_tools:
        print(f"ğŸ”§ å·²åŠ è½½ {len(mcp_tools)} ä¸ª MCP å·¥å…·")
    
    # --- 1. å‘é‡æ£€ç´¢ ---
    retrieved_nodes = []
    max_score = 0.0
    
    if use_rag:
        try:
            vector_store = get_vector_store()
            index = VectorStoreIndex.from_vector_store(vector_store=vector_store)
            retriever = index.as_retriever(similarity_top_k=3)
            retrieved_nodes = retriever.retrieve(current_message)
            
            if retrieved_nodes:
                max_score = max(node.score for node in retrieved_nodes if node.score is not None)
                print(f"Vector Retrieval: max_score={max_score:.3f}, nodes={len(retrieved_nodes)}")
        except Exception as e:
            print(f"Retrieval Error: {e}")
    
    # --- 2. æ··åˆåˆ¤æ–­ï¼šå‘é‡åˆ†æ•° OR å…³é”®è¯åŒ¹é… ---
    VECTOR_THRESHOLD = 0.5  # å‘é‡ç›¸ä¼¼åº¦é˜ˆå€¼ (é«˜ï¼Œç”¨äºè¯­ä¹‰åŒ¹é…)
    
    # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨æ•°æ®åº“ä¸­ç›´æ¥å‘½ä¸­ (ç²¾ç¡®åŒ¹é…)
    keyword_match = False
    keyword_results = []
    is_exact_match = False  # æ ‡è®°æ˜¯å¦ç²¾ç¡®åŒ¹é…
    
    if current_message.strip() and len(current_message.strip()) > 2:
        try:
            from django.db import connection
            import re
            query_text = current_message.strip()
            
            # æ–¹æ³•1ï¼šç²¾ç¡®åŒ¹é…æ•´ä¸ªæŸ¥è¯¢
            with connection.cursor() as cursor:
                cursor.execute(
                    "SELECT text, metadata_ FROM data_document_embeddings WHERE text ILIKE %s LIMIT 3",
                    [f"%{query_text}%"]
                )
                rows = cursor.fetchall()
                
                if rows:
                    is_exact_match = True
                    print(f"Keyword Match (exact): found {len(rows)} documents")
                else:
                    # æ–¹æ³•2ï¼šå¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ‹†åˆ†å…³é”®è¯åŒ¹é…
                    chinese_chars = re.findall(r'[\u4e00-\u9fa5]', query_text)
                    chinese_str = ''.join(chinese_chars)
                    
                    if len(chinese_str) >= 4:
                        keywords = []
                        for i in range(0, len(chinese_str) - 1, 2):
                            keywords.append(chinese_str[i:i+2])
                        keywords = list(set(keywords))[:3]
                        
                        if len(keywords) >= 2:
                            conditions = " AND ".join([f"text ILIKE %s" for _ in keywords])
                            params = [f"%{kw}%" for kw in keywords]
                            cursor.execute(
                                f"SELECT text, metadata_ FROM data_document_embeddings WHERE {conditions} LIMIT 3",
                                params
                            )
                            rows = cursor.fetchall()
                            if rows:
                                is_exact_match = False  # æ¨¡ç³ŠåŒ¹é…
                                print(f"Keyword Match (fuzzy): found {len(rows)} docs with keywords {keywords}")
                
                if rows:
                    keyword_match = True
                    keyword_results = rows
        except Exception as e:
            print(f"Keyword search error: {e}")
    
    # --- 2. å†³ç­–é€»è¾‘ ---
    # ä¼˜å…ˆçº§ï¼šRAG > å·¥å…· > æ™®é€šå¯¹è¯
    # ä½¿ç”¨å‘é‡è¯­ä¹‰åŒ¹é…æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
    
    # è®¡ç®—ç”¨æˆ·é—®é¢˜å’Œå·¥å…·æè¿°çš„ç›¸ä¼¼åº¦
    tool_match_score = 0.0
    matched_tool_name = None
    
    if mcp_tools and embed_model:
        try:
            # æŠŠç”¨æˆ·é—®é¢˜åšæˆ embedding
            query_embedding = embed_model.get_text_embedding(current_message)
            
            # è®¡ç®—å’Œæ¯ä¸ªå·¥å…·æè¿°çš„ç›¸ä¼¼åº¦
            for tool in mcp_tools:
                tool_desc = f"{tool.metadata.name}: {tool.metadata.description or ''}"
                tool_embedding = embed_model.get_text_embedding(tool_desc)
                
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                import numpy as np
                similarity = np.dot(query_embedding, tool_embedding) / (
                    np.linalg.norm(query_embedding) * np.linalg.norm(tool_embedding)
                )
                
                if similarity > tool_match_score:
                    tool_match_score = similarity
                    matched_tool_name = tool.metadata.name
            
            print(f"Tool Match: max_score={tool_match_score:.3f}, tool={matched_tool_name}")
        except Exception as e:
            print(f"Tool matching error: {e}")
    
    # å†³ç­–é˜ˆå€¼
    TOOL_THRESHOLD = 0.4  # å·¥å…·åŒ¹é…é˜ˆå€¼ï¼Œé™ä½ä»¥æ›´å®¹æ˜“è§¦å‘
    RAG_THRESHOLD = 0.5   # RAG é˜ˆå€¼
    
    # å†³ç­–é€»è¾‘ï¼šæ¯”è¾ƒåˆ†æ•°ï¼Œé€‰æ›´é«˜çš„
    # å¦‚æœéƒ½ä½äºé˜ˆå€¼ â†’ æ™®é€šå¯¹è¯
    rag_score = max_score if max_score >= RAG_THRESHOLD or (keyword_match and max_score >= 0.3) else 0
    tool_score = tool_match_score if tool_match_score >= TOOL_THRESHOLD else 0
    
    if rag_score > 0 and rag_score >= tool_score:
        selected_mode = "rag"
    elif tool_score > 0 and tool_score > rag_score:
        selected_mode = "tool"
    else:
        selected_mode = "chat"
    
    print(f"Router Decision: {selected_mode} (rag={rag_score:.3f}, tool={tool_score:.3f})")
    
    full_response_text = ""
    sources = []

    try:
        # 1. RAG åˆ†æ”¯ï¼ˆçŸ¥è¯†åº“é—®ç­”ï¼‰
        if selected_mode == "rag":
            print(f"  â†’ RAG: ä½¿ç”¨çŸ¥è¯†åº“å›ç­” (exact={is_exact_match})")
            
            if keyword_match and keyword_results:
                rag_texts = [row[0] for row in keyword_results]
                rag_context = "\n\nå‚è€ƒèµ„æ–™:\n" + "\n---\n".join(rag_texts)
                import json as json_lib
                for row in keyword_results:
                    try:
                        raw_meta = row[1]
                        meta = json_lib.loads(raw_meta) if isinstance(raw_meta, str) else (raw_meta if isinstance(raw_meta, dict) else {})
                        file_name = meta.get("file_name") or meta.get("title") or "æœªçŸ¥æ–‡ä»¶"
                        if "/" in str(file_name): file_name = str(file_name).split("/")[-1]
                        source_info = {"file_name": file_name, "page": meta.get("page_label")}
                        if source_info not in sources: sources.append(source_info)
                    except: pass
            else:
                rag_texts = [n.get_content() for n in retrieved_nodes]
                rag_context = "\n\nå‚è€ƒèµ„æ–™:\n" + "\n---\n".join(rag_texts)
                for node in retrieved_nodes:
                    meta = node.node.metadata if hasattr(node.node, 'metadata') else {}
                    file_name = meta.get("file_name") or "æœªçŸ¥æ–‡ä»¶"
                    if "/" in str(file_name): file_name = str(file_name).split("/")[-1]
                    source_info = {"file_name": file_name, "page": meta.get("page_label")}
                    if source_info not in sources: sources.append(source_info)
            
            import datetime
            current_time_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # è·å–å”¯ä¸€çš„æ–‡æ¡£æ¥æº
            unique_files = list(set([s.get("file_name", "æœªçŸ¥") for s in sources]))
            
            # æ ¹æ®åŒ¹é…ç±»å‹å’Œæ¥æºæ•°é‡æ„é€ ä¸åŒçš„ System Prompt
            if is_exact_match:
                # ç²¾ç¡®åŒ¹é…ï¼Œç›´æ¥å›ç­”
                system_prompt = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´æ˜¯: {current_time_str}ã€‚è¯·æ ¹æ®å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ï¼Œä½¿ç”¨ Markdown æ ¼å¼ã€‚"
            elif len(unique_files) > 1:
                # æ¨¡ç³ŠåŒ¹é… + å¤šä¸ªæ–‡æ¡£æ¥æºï¼Œè®©ç”¨æˆ·é€‰æ‹©
                files_list = "\n".join([f"- {f}" for f in unique_files])
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´æ˜¯: {current_time_str}ã€‚
æ³¨æ„ï¼šç”¨æˆ·çš„æŸ¥è¯¢æ˜¯æ¨¡ç³ŠåŒ¹é…çš„ç»“æœï¼Œæˆ‘åœ¨ä»¥ä¸‹å¤šä¸ªæ–‡æ¡£ä¸­æ‰¾åˆ°äº†ç›¸å…³ä¿¡æ¯ï¼š
{files_list}

è¯·å…ˆè¯¢é—®ç”¨æˆ·æƒ³è¦æŸ¥è¯¢å“ªä¸ªæ–‡æ¡£çš„ä¿¡æ¯ï¼Œä¸è¦ç›´æ¥ç»™å‡ºç­”æ¡ˆã€‚ç”¨ç®€æ´çš„æ–¹å¼åˆ—å‡ºè¿™äº›æ–‡æ¡£è®©ç”¨æˆ·é€‰æ‹©ã€‚"""
            else:
                # æ¨¡ç³ŠåŒ¹é… + å•ä¸€æ–‡æ¡£ï¼Œè¯¢é—®ç¡®è®¤
                doc_name = unique_files[0] if unique_files else "çŸ¥è¯†åº“"
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´æ˜¯: {current_time_str}ã€‚
æ³¨æ„ï¼šç”¨æˆ·çš„æŸ¥è¯¢æ˜¯æ¨¡ç³ŠåŒ¹é…çš„ç»“æœï¼Œæˆ‘åœ¨ã€Š{doc_name}ã€‹ä¸­æ‰¾åˆ°äº†å¯èƒ½ç›¸å…³çš„ä¿¡æ¯ã€‚
è¯·å…ˆç®€è¦è¯´æ˜æ‰¾åˆ°äº†ä»€ä¹ˆå†…å®¹ï¼Œå¹¶è¯¢é—®ç”¨æˆ·æ˜¯å¦æ˜¯ä»–ä»¬æƒ³è¦çš„ä¿¡æ¯ã€‚å¦‚æœç”¨æˆ·ç¡®è®¤ï¼Œå†è¯¦ç»†å›ç­”ã€‚"""
            
            messages = [LlamaChatMessage(role="system", content=system_prompt)]
            messages.extend(history)
            messages.append(LlamaChatMessage(role="user", content=f"{current_message}\n{rag_context}"))
            
            response_stream = llm.stream_chat(messages)
            for chunk in response_stream:
                if chunk.delta:
                    full_response_text += chunk.delta
                    yield json.dumps({"text": chunk.delta}, ensure_ascii=False) + "\n"
        
        # 2. å·¥å…·åˆ†æ”¯
        elif selected_mode == "tool":
            print(f"  â†’ Tool: è°ƒç”¨å·¥å…· {matched_tool_name}")
            
            try:
                # æ„é€ åŒ…å«ç³»ç»Ÿæç¤ºçš„å†å²
                system_msg = LlamaChatMessage(
                    role="system",
                    content="ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿè°ƒç”¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚å½“ç”¨æˆ·è¯¢é—®å¤©æ°”ã€åœ°å›¾ã€ä½ç½®ç­‰ä¿¡æ¯æ—¶ï¼Œè°ƒç”¨æä¾›çš„å·¥å…·è·å–å®æ—¶æ•°æ®ã€‚å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›å¿…è¦çš„å‚æ•°ï¼ˆå¦‚åŸå¸‚åï¼‰ï¼Œè¯·å…ˆè¯¢é—®ç”¨æˆ·ã€‚"
                )
                tool_history = [system_msg] + list(history)
                
                # ä½¿ç”¨ LLM function calling
                response = llm.chat_with_tools(
                    tools=mcp_tools,
                    user_msg=current_message,
                    chat_history=tool_history,
                )
                
                # å°è¯•è·å– tool callsï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºåˆ—è¡¨
                try:
                    tool_calls = llm.get_tool_calls_from_response(response)
                except:
                    tool_calls = []
                
                if tool_calls:
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_results = []
                    for tc in tool_calls:
                        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tc.tool_name}({tc.tool_kwargs})")

                        # è®°å½•æ¥æº
                        tool_map = get_tool_server_map()
                        server_name = tool_map.get(tc.tool_name, tc.tool_name)
                        
                        sources.append({
                            "type": "tool",
                            "name": server_name, # æ˜¾ç¤ºæœåŠ¡å (å¦‚ é«˜å¾·åœ°å›¾)
                            "tool_id": tc.tool_name, # åŸå§‹å·¥å…·ID
                            "args": str(tc.tool_kwargs)
                        })
                        
                        # æ‰¾åˆ°å¹¶æ‰§è¡Œå·¥å…·
                        for tool in mcp_tools:
                            if tool.metadata.name == tc.tool_name:
                                try:
                                    result = tool.call(**tc.tool_kwargs)
                                    tool_results.append(f"{tc.tool_name}: {result}")
                                except Exception as te:
                                    tool_results.append(f"{tc.tool_name} å¤±è´¥: {te}")
                                break
                    
                    # ç”¨å·¥å…·ç»“æœç”Ÿæˆå›ç­”
                    tool_context = "\n".join(tool_results)
                    import datetime
                    current_time_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    
                    messages = [
                        LlamaChatMessage(role="system", content=f"ä½ æ˜¯åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´æ˜¯: {current_time_str}ã€‚æ ¹æ®å·¥å…·è¿”å›çš„ä¿¡æ¯å›ç­”ç”¨æˆ·ã€‚"),
                        LlamaChatMessage(role="user", content=current_message),
                        LlamaChatMessage(role="assistant", content=f"å·¥å…·è¿”å›:\n{tool_context}"),
                        LlamaChatMessage(role="user", content="è¯·ç”¨è¿™äº›ä¿¡æ¯å›ç­”æˆ‘ã€‚")
                    ]
                    response_stream = llm.stream_chat(messages)
                    for chunk in response_stream:
                        if chunk.delta:
                            full_response_text += chunk.delta
                            yield json.dumps({"text": chunk.delta}, ensure_ascii=False) + "\n"
                else:
                    # LLM åˆ¤æ–­ä¸éœ€è¦å·¥å…·
                    full_response_text = str(response.message.content)
                    for i in range(0, len(full_response_text), 50):
                        yield json.dumps({"text": full_response_text[i:i+50]}, ensure_ascii=False) + "\n"
                        
            except Exception as e:
                print(f"Tool error: {e}")
                # é™çº§åˆ°æ™®é€šå¯¹è¯
                messages = [LlamaChatMessage(role="system", content="ä½ æ˜¯åŠ©æ‰‹ã€‚")]
                messages.extend(history)
                messages.append(LlamaChatMessage(role="user", content=current_message))
                response_stream = llm.stream_chat(messages)
                for chunk in response_stream:
                    if chunk.delta:
                        full_response_text += chunk.delta
                        yield json.dumps({"text": chunk.delta}, ensure_ascii=False) + "\n"
        
        # 3. æ™®é€šå¯¹è¯ï¼ˆæœ€å¿«ï¼‰
        else:
            print("Router Decision: chat")
            import datetime
            current_time_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            system_prompt = f"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´æ˜¯: {current_time_str}ã€‚"
            messages = [LlamaChatMessage(role="system", content=system_prompt)]
            messages.extend(history)
            messages.append(LlamaChatMessage(role="user", content=current_message))
            
            response_stream = llm.stream_chat(messages)
            for chunk in response_stream:
                if chunk.delta:
                    full_response_text += chunk.delta
                    yield json.dumps({"text": chunk.delta}, ensure_ascii=False) + "\n"

        # å‘é€ Sources å’Œä¿å­˜
        if sources:
            yield json.dumps({"sources": sources}, ensure_ascii=False) + "\n"
        
        if session_id:
            try:
                session = ChatSession.objects.get(id=session_id)
                elapsed_time = int((time.time() - start_time) * 1000) # è®¡ç®—è€—æ—¶ (ms)
                ChatMessage.objects.create(
                    session=session, 
                    role='ai', 
                    content=full_response_text, 
                    sources=sources,
                    elapsed_time=elapsed_time
                )
                if session.title == "New Chat":
                    session.title = current_message.strip()[:20] + ("..." if len(current_message) > 20 else "")
                    session.save(update_fields=['title'])
            except: pass

    except Exception as e:
        yield json.dumps({"text": f"Error: {str(e)}"}, ensure_ascii=False) + "\n"



@router.post("/stream", summary="æµå¼å¯¹è¯ (å¸¦è®°å¿†)")
def chat_stream(request, payload: ChatRequest):
    # 1. è·å–æˆ–åˆ›å»º Session
    from django.core.exceptions import ValidationError
    
    session_id = payload.session_id
    session = None
    
    # è·å–å½“å‰ç”¨æˆ·ï¼ˆå¦‚æœå·²è®¤è¯ï¼‰
    current_user = get_current_user_from_request(request)
    
    if session_id:
        try:
            # å°è¯•è·å–ç°æœ‰ Session
            session = ChatSession.objects.get(id=session_id)
            # å¦‚æœä¼šè¯æ²¡æœ‰ç”¨æˆ·ä½†å½“å‰ç”¨æˆ·å·²ç™»å½•ï¼Œå…³è”ç”¨æˆ·
            if not session.user and current_user:
                session.user = current_user
                session.save(update_fields=['user'])
        except (ChatSession.DoesNotExist, ValidationError):
            # å¦‚æœä¸å­˜åœ¨ æˆ– æ ¼å¼ä¸å¯¹ï¼Œæˆ‘ä»¬å°±å°è¯•æ–°å»º
            try:
                # å°è¯•ç”¨ä¼ æ¥çš„ session_id åˆ›å»ºå¯èƒ½ä¼šå†æ¬¡å¤±è´¥ï¼ˆå¦‚æœæ ¼å¼ä¸å¯¹ï¼‰
                uuid.UUID(session_id) # éªŒè¯ä¸€ä¸‹æ ¼å¼
                session = ChatSession.objects.create(id=session_id, user=current_user)
            except (ValueError, ValidationError):
                # å½»åº•æ”¾å¼ƒåŸæ¥çš„ IDï¼Œç”Ÿæˆæ–°çš„
                session = ChatSession.objects.create(user=current_user)
                session_id = str(session.id)
    else:
        # å¦‚æœå‰ç«¯æ²¡ä¼  IDï¼Œæˆ‘ä»¬æ–°å»ºä¸€ä¸ª
        session = ChatSession.objects.create(user=current_user)
        session_id = str(session.id)

    # 2. è·å–ç”¨æˆ·æœ€æ–°çš„ä¸€æ¡æ¶ˆæ¯
    # ä¹‹å‰çš„ payload.messages æ˜¯ä¸ªåˆ—è¡¨ï¼Œä½†ç°åœ¨æœ‰äº†å†å²è®°å½•ï¼Œå‰ç«¯å…¶å®åªéœ€è¦å‘æœ€æ–°çš„ä¸€å¥ user message å³å¯ã€‚
    # ä¸ºäº†å…¼å®¹æ—§é€»è¾‘ï¼Œæˆ‘ä»¬å– messages åˆ—è¡¨é‡Œæœ€åä¸€æ¡ user æ¶ˆæ¯ã€‚
    user_text = ""
    if payload.messages:
        user_text = payload.messages[-1].text
    
    if not user_text:
        return {"error": "No user message found"}

    # 3. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
    ChatMessage.objects.create(
        session=session,
        role='user',
        content=user_text
    )

    # 4. åŠ è½½å†å²è®°å½• (ä¸åŒ…å«åˆšåˆšå­˜çš„è¿™æ¡ï¼Œå› ä¸ºè¦ä½œä¸º prompt å•ç‹¬ä¼ )
    # LlamaIndex stream_chat(message, history) é‡Œçš„ history æŒ‡çš„æ˜¯ "Previous conversation"
    history = get_chat_history(session_id)
    # å»æ‰åˆšåˆšå­˜çš„é‚£æ¡ user messageï¼Œé˜²æ­¢é‡å¤ (å› ä¸º get_chat_history ä¼šå–æ‰€æœ‰)
    if history and history[-1].role == "user" and history[-1].content == user_text:
        history.pop()

    # 5. è¿”å›æµå¼å“åº”
    # æˆ‘ä»¬éœ€è¦åœ¨ header é‡ŒæŠŠ session_id è¿”ç»™å‰ç«¯å—ï¼Ÿ
    # Stream Response å¾ˆéš¾å¸¦ Headerã€‚
    # å»ºè®®å‰ç«¯ï¼šå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆæ²¡ session_idï¼‰ï¼Œå‰ç«¯æ”¶åˆ°ç¬¬ä¸€å¸§æ•°æ®æ—¶åº”è¯¥çŸ¥é“ session_idï¼ˆæˆ–è€…æˆ‘ä»¬ç¬¬ä¸€å¸§å‘ä¸ªå…ƒæ•°æ®ï¼Ÿï¼‰
    # ç®€å•ç­–ç•¥ï¼šå‰ç«¯è‡ªå·±ç”Ÿæˆ UUID session_id ä¼ è¿‡æ¥ï¼ˆUUIDv4ï¼‰ï¼Œè¿™æ ·åç«¯å°±ä¸ç”¨å›ä¼ äº†ã€‚
    
    return StreamingHttpResponse(
        stream_generator(user_text, history, payload.model, payload.use_rag, session_id),
        content_type='text/plain; charset=utf-8'
    )

@router.get("/history", response=List[MessageSchema])
def get_history(request, session_id: str):
    """è·å–ä¼šè¯å†å²"""
    from django.core.exceptions import ValidationError
    try:
        # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        current_user = get_current_user_from_request(request)
        session = ChatSession.objects.filter(id=session_id).first()
        
        # å¦‚æœä¼šè¯å­˜åœ¨ä¸”æœ‰ç”¨æˆ·å½’å±ï¼ŒéªŒè¯æ˜¯å¦ä¸ºå½“å‰ç”¨æˆ·
        if session and session.user and current_user and session.user != current_user:
            return []  # æ— æƒè®¿é—®å…¶ä»–ç”¨æˆ·çš„ä¼šè¯
        
        messages = ChatMessage.objects.filter(session_id=session_id).order_by('created_at')
        return [
            {
                "role": msg.role, 
                "text": msg.content if msg.content else "",
                "sources": msg.sources,
                "elapsed": msg.elapsed_time
            }
            for msg in messages
        ]
    except ValidationError:
        return [] # ID æ ¼å¼ä¸å¯¹å°±è¿”å›ç©º
    except Exception as e:
        print(f"Error getting history: {e}")
        return []

@router.delete("/session/{session_id}", summary="åˆ é™¤ä¼šè¯")
def delete_session(request, session_id: str):
    """åˆ é™¤æŒ‡å®šä¼šè¯åŠå…¶æ‰€æœ‰æ¶ˆæ¯ï¼ˆä»…é™å½“å‰ç”¨æˆ·ï¼‰"""
    from django.core.exceptions import ValidationError
    try:
        current_user = get_current_user_from_request(request)
        
        # éªŒè¯ä¼šè¯å±äºå½“å‰ç”¨æˆ·
        session = ChatSession.objects.filter(id=session_id).first()
        if session and session.user and current_user and session.user != current_user:
            return {"success": False, "error": "Permission denied"}
        
        # åˆ é™¤æ‰€æœ‰æ¶ˆæ¯
        deleted_count, _ = ChatMessage.objects.filter(session_id=session_id).delete()
        # åˆ é™¤ä¼šè¯
        ChatSession.objects.filter(id=session_id).delete()
        return {"success": True, "deleted_messages": deleted_count}
    except ValidationError:
        return {"success": False, "error": "Invalid session ID"}
    except Exception as e:
        print(f"Error deleting session: {e}")
        return {"success": False, "error": str(e)}

@router.get("/sessions", response=List[SessionSchema], summary="è·å–ä¼šè¯åˆ—è¡¨")
def get_sessions(request):
    """è·å–å½“å‰ç”¨æˆ·çš„ä¼šè¯åˆ—è¡¨"""
    from django.db.models import Count, Q
    
    # è·å–å½“å‰ç”¨æˆ·
    current_user = get_current_user_from_request(request)
    
    # åªè¿”å›å½“å‰ç”¨æˆ·çš„ä¼šè¯ï¼ˆå¦‚æœå·²ç™»å½•ï¼‰æˆ–åŒ¿åä¼šè¯
    if current_user:
        sessions = ChatSession.objects.filter(
            is_active=True,
            user=current_user
        ).annotate(
            message_count=Count('messages')
        ).order_by('-updated_at')[:20]
    else:
        # æœªç™»å½•ç”¨æˆ·çœ‹ä¸åˆ°ä»»ä½•ä¼šè¯
        return []
    
    return [
        {
            "id": str(session.id),
            "title": session.title,
            "updated_at": session.updated_at.isoformat(),
            "message_count": session.message_count
        }
        for session in sessions
    ]

@router.patch("/session/{session_id}/title", summary="æ›´æ–°ä¼šè¯æ ‡é¢˜")
def update_session_title(request, session_id: str, title: str):
    """æ›´æ–°ä¼šè¯æ ‡é¢˜"""
    from django.core.exceptions import ValidationError
    try:
        session = ChatSession.objects.get(id=session_id)
        session.title = title
        session.save(update_fields=['title'])
        return {"success": True}
    except ChatSession.DoesNotExist:
        return {"success": False, "error": "Session not found"}
    except Exception as e:
        return {"success": False, "error": str(e)}

